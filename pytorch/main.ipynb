{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "ML2021Spring - HW1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('py38': conda)"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "b1d710d4a2dd0e836743a9708dcf2dd87750cb6db75a03dbc0a1931aaec4e6cb"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from utils.mylib import *\n",
        "from d2l import torch as d2l"
      ],
      "outputs": [],
      "metadata": {
        "id": "k-onQd4JNA5H",
        "outputId": "0317f255-2dd4-4eeb-822f-ed20d8ea782b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "init_Seed()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU ready!\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "class MLDataset(Dataset):\n",
        "    \"\"\" Dataset for loading and preprocessing the MoviesLen dataset. \"\"\"\n",
        "    def __init__(self, path, mode='train', target_only=False):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "\n",
        "        # Read data into numpy arrays\n",
        "        data = np.loadtxt(path, dtype='long')\n",
        "\n",
        "        # Convert data into PyTorch tensors\n",
        "        self.data = torch.LongTensor(data[:, :2])\n",
        "        self.target = torch.FloatTensor(data[:, 2])\n",
        " \n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "\n",
        "        print('Finished reading the {} set of MoviesLen Dataset ({} samples found, each dim = {})'\n",
        "              .format(mode, len(self.data), self.dim))\n",
        "    \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]\n",
        "    \n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns the size of the dataset\n",
        "        return len(self.data)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "class MF(nn.Module):\n",
        "    def __init__(self, n_users=1000, m_items=2000, n_factors=20):\n",
        "        super(MF, self).__init__()\n",
        "\n",
        "        self.U = torch.nn.Embedding(n_users, n_factors)\n",
        "        self.V = torch.nn.Embedding(m_items, n_factors)\n",
        "\n",
        "        self.U.weight.data.uniform_(-0.005, 0.005)\n",
        "        self.V.weight.data.uniform_(-0.005, 0.005)\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "    \n",
        "    def forward(self, user, item):\n",
        "        # return (self.user_factors(user) * self.item_factors(item)).sum(1)\n",
        "        return torch.einsum('ij, ij -> i', [self.U(user), self.V(item)])\n",
        "    \n",
        "    def cal_loss(self, pred, target):\n",
        "        ''' Calculate loss '''\n",
        "        return self.criterion(pred, target)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DataLoader**\n",
        "\n",
        "A `DataLoader` loads data from a given `Dataset` into batches.\n"
      ],
      "metadata": {
        "id": "AlhTlkE7MDo3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = MLDataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
        "    dataloader = DataLoader(dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
        "    return dataloader"
      ],
      "outputs": [],
      "metadata": {
        "id": "hlhLk5t6MBX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train/Dev/Test**"
      ],
      "metadata": {
        "id": "DvFWVjZ5Nvga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# U = torch.rand(size=(1005, 20), requires_grad=True)\n",
        "# V = torch.rand(size=(2005, 20), requires_grad=True)\n",
        "# with torch.no_grad():\n",
        "#     U /= 100\n",
        "#     V /= 100"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "MAM8QecJOyqn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# def model(X):\n",
        "#     return torch.einsum('ij, ij -> i', [U[X[:, 0]], V[X[:, 1]]])\n",
        "\n",
        "# def squared_loss(y_hat, y):  #@save\n",
        "#     \"\"\"Squared loss.\"\"\"\n",
        "#     return (y_hat - y.reshape(y_hat.shape))**2 / 2\n",
        "\n",
        "# def objective(X, y):\n",
        "#     return squared_loss(model(X), y).sum() + (U[X[:, 0]].norm() ** 2 + V[X[:, 1]].norm() ** 2) * 0.01\n",
        "\n",
        "# def sgd(params, lr, batch_size):  #@save\n",
        "#     \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
        "#     with torch.no_grad():\n",
        "#         for param in params:\n",
        "#             param -= lr * param.grad\n",
        "#             param.grad.zero_()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "def train(tr_set, dv_set, model, config):\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "    \n",
        "    # Setup optimizer\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    min_mse = 1000.\n",
        "    loss_record = {'train': [], 'dev': []} \n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "\n",
        "    while epoch < n_epochs:\n",
        "        model.train()\n",
        "        for X, y in tr_set:\n",
        "            optimizer.zero_grad()    \n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = model(X[:, 0], X[:, 1])\n",
        "            mse_loss = model.cal_loss(y_hat, y)\n",
        "            mse_loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "        \n",
        "        epoch += 1\n",
        "        \n",
        "        print(\"train_loss: {:.4f}\".format(np.mean(loss_record['train'][-100:])))\n",
        "\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            min_mse = dev_mse\n",
        "            early_stop_cnt = 0\n",
        "            print(\"Saving model (epoch = {:4d}  loss = {:.4f} )\".format(epoch, dev_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "        \n",
        "        \n",
        "        loss_record['dev'].append(dev_mse)\n",
        "\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            break\n",
        "\n",
        "    print(\"Finish training after {} epochs\".format(epoch))\n",
        "    return min_mse, loss_record"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# def train2():\n",
        "#     n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "#     loss = squared_loss\n",
        "        \n",
        "#     # Setup optimizer\n",
        "#     optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "#         [U, V], **config['optim_hparas'])\n",
        "\n",
        "#     min_mse = 1000.\n",
        "#     loss_record = {'train': [], 'dev': []} \n",
        "#     early_stop_cnt = 0\n",
        "#     epoch = 0\n",
        "\n",
        "#     while epoch < n_epochs:\n",
        "\n",
        "#         for X, y in tr_set:\n",
        "#             optimizer.zero_grad()\n",
        "#             X, y = X.to(device), y.to(device)\n",
        "#             y_hat = model(X)\n",
        "#             mse_loss = loss(y_hat, y)\n",
        "#             mse_loss.sum().backward()\n",
        "#             optimizer.step()\n",
        "            \n",
        "#         epoch += 1\n",
        "        \n",
        "#         with torch.no_grad():\n",
        "#             train_l = loss(model(X), y)\n",
        "#             print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validation**"
      ],
      "metadata": {
        "id": "0hSd4Bn3O2PL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for X, y in dv_set:                         # iterate through the dataloader\n",
        "        X, y = X.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(X[:, 0], X[:, 1])                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(X)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ],
      "outputs": [],
      "metadata": {
        "id": "yrxrD3YsN3U2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing**"
      ],
      "metadata": {
        "id": "g0pdrhQAO41L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "def test(tt_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    preds = []\n",
        "    for x in tt_set:                            # iterate through the dataloader\n",
        "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            preds.append(pred.detach().cpu())   # collect prediction\n",
        "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
        "    return preds"
      ],
      "outputs": [],
      "metadata": {
        "id": "aSBMRFlYN5tB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup Hyper-parameters**\n",
        "\n",
        "`config` contains hyper-parameters for training and the path to save your model."
      ],
      "metadata": {
        "id": "SvckkF5dvf0j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "target_only = False                   # TODO: Using 40 states & 2 tested_positive features\n",
        "\n",
        "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
        "config = {\n",
        "    'n_epochs': 2000,              # maximum number of epochs\n",
        "    'batch_size': 1000,               # mini-batch size for dataloader\n",
        "    'optimizer': 'Adam',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        # 'lr': 1,                 # learning rate of SGD\n",
        "        'weight_decay': 0.0001\n",
        "        # 'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 30,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ],
      "outputs": [],
      "metadata": {
        "id": "NPXpdumwPjE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load data and model**"
      ],
      "metadata": {
        "id": "6j1eOV3TOH-j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "tr_set = prep_dataloader('../data/ML100K/ML100K_copy1_train.txt', 'train', config['batch_size'], target_only=target_only)\n",
        "dv_set = prep_dataloader('../data/ML100K/ML100K_copy1_test.txt', 'dev', config['batch_size'], target_only=target_only)\n",
        "# tt_set = prep_dataloader(\"data/ML100K/ML100K_copy1_test.txt\", 'test', config['batch_size'], target_only=target_only)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished reading the train set of MoviesLen Dataset (60000 samples found, each dim = 2)\n",
            "Finished reading the dev set of MoviesLen Dataset (20000 samples found, each dim = 2)\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "model = MF().to(device) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start Training!**"
      ],
      "metadata": {
        "id": "sX2B_zgSOPTJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "# model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrEbUxazQAAZ",
        "outputId": "2190df3d-28a1-4849-a9a8-5179cff3130d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "%%time\n",
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 13.7021\n",
            "Saving model (epoch =    1  loss = 13.5217 )\n",
            "train_loss: 13.2614\n",
            "Saving model (epoch =    2  loss = 12.0933 )\n",
            "train_loss: 11.6354\n",
            "Saving model (epoch =    3  loss = 9.5159 )\n",
            "train_loss: 9.0623\n",
            "Saving model (epoch =    4  loss = 6.6277 )\n",
            "train_loss: 6.2636\n",
            "Saving model (epoch =    5  loss = 4.2326 )\n",
            "train_loss: 3.9970\n",
            "Saving model (epoch =    6  loss = 2.6963 )\n",
            "train_loss: 2.5579\n",
            "Saving model (epoch =    7  loss = 1.9019 )\n",
            "train_loss: 1.8066\n",
            "Saving model (epoch =    8  loss = 1.5314 )\n",
            "train_loss: 1.4391\n",
            "Saving model (epoch =    9  loss = 1.3464 )\n",
            "train_loss: 1.2573\n",
            "Saving model (epoch =   10  loss = 1.2383 )\n",
            "train_loss: 1.1523\n",
            "Saving model (epoch =   11  loss = 1.1696 )\n",
            "train_loss: 1.0756\n",
            "Saving model (epoch =   12  loss = 1.1220 )\n",
            "train_loss: 1.0323\n",
            "Saving model (epoch =   13  loss = 1.0880 )\n",
            "train_loss: 0.9948\n",
            "Saving model (epoch =   14  loss = 1.0619 )\n",
            "train_loss: 0.9704\n",
            "Saving model (epoch =   15  loss = 1.0429 )\n",
            "train_loss: 0.9480\n",
            "Saving model (epoch =   16  loss = 1.0273 )\n",
            "train_loss: 0.9319\n",
            "Saving model (epoch =   17  loss = 1.0160 )\n",
            "train_loss: 0.9203\n",
            "Saving model (epoch =   18  loss = 1.0068 )\n",
            "train_loss: 0.9089\n",
            "Saving model (epoch =   19  loss = 0.9991 )\n",
            "train_loss: 0.8997\n",
            "Saving model (epoch =   20  loss = 0.9932 )\n",
            "train_loss: 0.8954\n",
            "Saving model (epoch =   21  loss = 0.9879 )\n",
            "train_loss: 0.8912\n",
            "Saving model (epoch =   22  loss = 0.9838 )\n",
            "train_loss: 0.8854\n",
            "Saving model (epoch =   23  loss = 0.9808 )\n",
            "train_loss: 0.8804\n",
            "Saving model (epoch =   24  loss = 0.9784 )\n",
            "train_loss: 0.8767\n",
            "Saving model (epoch =   25  loss = 0.9756 )\n",
            "train_loss: 0.8735\n",
            "Saving model (epoch =   26  loss = 0.9733 )\n",
            "train_loss: 0.8725\n",
            "Saving model (epoch =   27  loss = 0.9716 )\n",
            "train_loss: 0.8662\n",
            "Saving model (epoch =   28  loss = 0.9702 )\n",
            "train_loss: 0.8679\n",
            "Saving model (epoch =   29  loss = 0.9691 )\n",
            "train_loss: 0.8682\n",
            "Saving model (epoch =   30  loss = 0.9678 )\n",
            "train_loss: 0.8651\n",
            "Saving model (epoch =   31  loss = 0.9667 )\n",
            "train_loss: 0.8691\n",
            "Saving model (epoch =   32  loss = 0.9664 )\n",
            "train_loss: 0.8635\n",
            "Saving model (epoch =   33  loss = 0.9650 )\n",
            "train_loss: 0.8596\n",
            "Saving model (epoch =   34  loss = 0.9645 )\n",
            "train_loss: 0.8621\n",
            "Saving model (epoch =   35  loss = 0.9638 )\n",
            "train_loss: 0.8615\n",
            "Saving model (epoch =   36  loss = 0.9636 )\n",
            "train_loss: 0.8536\n",
            "Saving model (epoch =   37  loss = 0.9630 )\n",
            "train_loss: 0.8589\n",
            "Saving model (epoch =   38  loss = 0.9627 )\n",
            "train_loss: 0.8573\n",
            "Saving model (epoch =   39  loss = 0.9622 )\n",
            "train_loss: 0.8593\n",
            "train_loss: 0.8574\n",
            "Saving model (epoch =   41  loss = 0.9615 )\n",
            "train_loss: 0.8543\n",
            "Saving model (epoch =   42  loss = 0.9611 )\n",
            "train_loss: 0.8550\n",
            "train_loss: 0.8565\n",
            "Saving model (epoch =   44  loss = 0.9605 )\n",
            "train_loss: 0.8593\n",
            "train_loss: 0.8550\n",
            "Saving model (epoch =   46  loss = 0.9603 )\n",
            "train_loss: 0.8558\n",
            "Saving model (epoch =   47  loss = 0.9598 )\n",
            "train_loss: 0.8546\n",
            "train_loss: 0.8540\n",
            "train_loss: 0.8542\n",
            "Saving model (epoch =   50  loss = 0.9595 )\n",
            "train_loss: 0.8560\n",
            "Saving model (epoch =   51  loss = 0.9594 )\n",
            "train_loss: 0.8531\n",
            "Saving model (epoch =   52  loss = 0.9591 )\n",
            "train_loss: 0.8555\n",
            "Saving model (epoch =   53  loss = 0.9590 )\n",
            "train_loss: 0.8547\n",
            "train_loss: 0.8527\n",
            "train_loss: 0.8548\n",
            "Saving model (epoch =   56  loss = 0.9586 )\n",
            "train_loss: 0.8513\n",
            "train_loss: 0.8552\n",
            "train_loss: 0.8544\n",
            "train_loss: 0.8532\n",
            "Saving model (epoch =   60  loss = 0.9585 )\n",
            "train_loss: 0.8506\n",
            "train_loss: 0.8521\n",
            "Saving model (epoch =   62  loss = 0.9584 )\n",
            "train_loss: 0.8530\n",
            "Saving model (epoch =   63  loss = 0.9582 )\n",
            "train_loss: 0.8495\n",
            "train_loss: 0.8506\n",
            "train_loss: 0.8507\n",
            "Saving model (epoch =   66  loss = 0.9581 )\n",
            "train_loss: 0.8549\n",
            "Saving model (epoch =   67  loss = 0.9580 )\n",
            "train_loss: 0.8490\n",
            "Saving model (epoch =   68  loss = 0.9575 )\n",
            "train_loss: 0.8526\n",
            "train_loss: 0.8520\n",
            "train_loss: 0.8519\n",
            "train_loss: 0.8503\n",
            "train_loss: 0.8503\n",
            "train_loss: 0.8491\n",
            "Saving model (epoch =   74  loss = 0.9574 )\n",
            "train_loss: 0.8485\n",
            "Saving model (epoch =   75  loss = 0.9572 )\n",
            "train_loss: 0.8490\n",
            "train_loss: 0.8508\n",
            "train_loss: 0.8481\n",
            "Saving model (epoch =   78  loss = 0.9570 )\n",
            "train_loss: 0.8481\n",
            "train_loss: 0.8480\n",
            "Saving model (epoch =   80  loss = 0.9564 )\n",
            "train_loss: 0.8481\n",
            "train_loss: 0.8453\n",
            "train_loss: 0.8488\n",
            "train_loss: 0.8492\n",
            "Saving model (epoch =   84  loss = 0.9561 )\n",
            "train_loss: 0.8454\n",
            "Saving model (epoch =   85  loss = 0.9561 )\n",
            "train_loss: 0.8480\n",
            "Saving model (epoch =   86  loss = 0.9559 )\n",
            "train_loss: 0.8455\n",
            "train_loss: 0.8446\n",
            "Saving model (epoch =   88  loss = 0.9553 )\n",
            "train_loss: 0.8426\n",
            "Saving model (epoch =   89  loss = 0.9552 )\n",
            "train_loss: 0.8445\n",
            "train_loss: 0.8422\n",
            "Saving model (epoch =   91  loss = 0.9541 )\n",
            "train_loss: 0.8416\n",
            "train_loss: 0.8416\n",
            "Saving model (epoch =   93  loss = 0.9539 )\n",
            "train_loss: 0.8403\n",
            "train_loss: 0.8410\n",
            "Saving model (epoch =   95  loss = 0.9534 )\n",
            "train_loss: 0.8393\n",
            "train_loss: 0.8390\n",
            "Saving model (epoch =   97  loss = 0.9525 )\n",
            "train_loss: 0.8362\n",
            "Saving model (epoch =   98  loss = 0.9524 )\n",
            "train_loss: 0.8353\n",
            "Saving model (epoch =   99  loss = 0.9521 )\n",
            "train_loss: 0.8362\n",
            "Saving model (epoch =  100  loss = 0.9512 )\n",
            "train_loss: 0.8327\n",
            "train_loss: 0.8311\n",
            "Saving model (epoch =  102  loss = 0.9508 )\n",
            "train_loss: 0.8317\n",
            "Saving model (epoch =  103  loss = 0.9502 )\n",
            "train_loss: 0.8318\n",
            "Saving model (epoch =  104  loss = 0.9495 )\n",
            "train_loss: 0.8284\n",
            "Saving model (epoch =  105  loss = 0.9492 )\n",
            "train_loss: 0.8277\n",
            "Saving model (epoch =  106  loss = 0.9483 )\n",
            "train_loss: 0.8279\n",
            "Saving model (epoch =  107  loss = 0.9482 )\n",
            "train_loss: 0.8219\n",
            "Saving model (epoch =  108  loss = 0.9471 )\n",
            "train_loss: 0.8251\n",
            "Saving model (epoch =  109  loss = 0.9465 )\n",
            "train_loss: 0.8204\n",
            "Saving model (epoch =  110  loss = 0.9462 )\n",
            "train_loss: 0.8215\n",
            "Saving model (epoch =  111  loss = 0.9450 )\n",
            "train_loss: 0.8210\n",
            "Saving model (epoch =  112  loss = 0.9440 )\n",
            "train_loss: 0.8187\n",
            "Saving model (epoch =  113  loss = 0.9434 )\n",
            "train_loss: 0.8132\n",
            "Saving model (epoch =  114  loss = 0.9427 )\n",
            "train_loss: 0.8082\n",
            "Saving model (epoch =  115  loss = 0.9423 )\n",
            "train_loss: 0.8081\n",
            "Saving model (epoch =  116  loss = 0.9408 )\n",
            "train_loss: 0.8080\n",
            "Saving model (epoch =  117  loss = 0.9399 )\n",
            "train_loss: 0.8031\n",
            "Saving model (epoch =  118  loss = 0.9391 )\n",
            "train_loss: 0.8019\n",
            "Saving model (epoch =  119  loss = 0.9383 )\n",
            "train_loss: 0.8009\n",
            "Saving model (epoch =  120  loss = 0.9370 )\n",
            "train_loss: 0.7968\n",
            "Saving model (epoch =  121  loss = 0.9363 )\n",
            "train_loss: 0.7933\n",
            "Saving model (epoch =  122  loss = 0.9355 )\n",
            "train_loss: 0.7905\n",
            "Saving model (epoch =  123  loss = 0.9346 )\n",
            "train_loss: 0.7888\n",
            "Saving model (epoch =  124  loss = 0.9342 )\n",
            "train_loss: 0.7851\n",
            "Saving model (epoch =  125  loss = 0.9327 )\n",
            "train_loss: 0.7839\n",
            "Saving model (epoch =  126  loss = 0.9320 )\n",
            "train_loss: 0.7803\n",
            "Saving model (epoch =  127  loss = 0.9307 )\n",
            "train_loss: 0.7764\n",
            "Saving model (epoch =  128  loss = 0.9299 )\n",
            "train_loss: 0.7733\n",
            "Saving model (epoch =  129  loss = 0.9287 )\n",
            "train_loss: 0.7699\n",
            "Saving model (epoch =  130  loss = 0.9284 )\n",
            "train_loss: 0.7707\n",
            "Saving model (epoch =  131  loss = 0.9270 )\n",
            "train_loss: 0.7665\n",
            "Saving model (epoch =  132  loss = 0.9259 )\n",
            "train_loss: 0.7630\n",
            "Saving model (epoch =  133  loss = 0.9254 )\n",
            "train_loss: 0.7588\n",
            "Saving model (epoch =  134  loss = 0.9244 )\n",
            "train_loss: 0.7588\n",
            "Saving model (epoch =  135  loss = 0.9239 )\n",
            "train_loss: 0.7529\n",
            "Saving model (epoch =  136  loss = 0.9231 )\n",
            "train_loss: 0.7479\n",
            "Saving model (epoch =  137  loss = 0.9224 )\n",
            "train_loss: 0.7450\n",
            "Saving model (epoch =  138  loss = 0.9208 )\n",
            "train_loss: 0.7427\n",
            "Saving model (epoch =  139  loss = 0.9204 )\n",
            "train_loss: 0.7399\n",
            "Saving model (epoch =  140  loss = 0.9202 )\n",
            "train_loss: 0.7368\n",
            "Saving model (epoch =  141  loss = 0.9195 )\n",
            "train_loss: 0.7331\n",
            "Saving model (epoch =  142  loss = 0.9184 )\n",
            "train_loss: 0.7317\n",
            "Saving model (epoch =  143  loss = 0.9181 )\n",
            "train_loss: 0.7245\n",
            "train_loss: 0.7261\n",
            "Saving model (epoch =  145  loss = 0.9174 )\n",
            "train_loss: 0.7198\n",
            "Saving model (epoch =  146  loss = 0.9165 )\n",
            "train_loss: 0.7141\n",
            "Saving model (epoch =  147  loss = 0.9161 )\n",
            "train_loss: 0.7132\n",
            "Saving model (epoch =  148  loss = 0.9157 )\n",
            "train_loss: 0.7090\n",
            "Saving model (epoch =  149  loss = 0.9147 )\n",
            "train_loss: 0.7084\n",
            "train_loss: 0.7006\n",
            "Saving model (epoch =  151  loss = 0.9139 )\n",
            "train_loss: 0.6981\n",
            "train_loss: 0.6965\n",
            "train_loss: 0.6902\n",
            "Saving model (epoch =  154  loss = 0.9139 )\n",
            "train_loss: 0.6886\n",
            "Saving model (epoch =  155  loss = 0.9136 )\n",
            "train_loss: 0.6856\n",
            "Saving model (epoch =  156  loss = 0.9131 )\n",
            "train_loss: 0.6809\n",
            "Saving model (epoch =  157  loss = 0.9130 )\n",
            "train_loss: 0.6776\n",
            "Saving model (epoch =  158  loss = 0.9121 )\n",
            "train_loss: 0.6716\n",
            "train_loss: 0.6685\n",
            "train_loss: 0.6673\n",
            "train_loss: 0.6605\n",
            "train_loss: 0.6560\n",
            "train_loss: 0.6527\n",
            "train_loss: 0.6485\n",
            "Saving model (epoch =  165  loss = 0.9119 )\n",
            "train_loss: 0.6452\n",
            "train_loss: 0.6403\n",
            "train_loss: 0.6375\n",
            "train_loss: 0.6350\n",
            "train_loss: 0.6289\n",
            "train_loss: 0.6272\n",
            "train_loss: 0.6208\n",
            "train_loss: 0.6185\n",
            "train_loss: 0.6126\n",
            "train_loss: 0.6077\n",
            "train_loss: 0.6064\n",
            "train_loss: 0.6018\n",
            "train_loss: 0.5970\n",
            "train_loss: 0.5925\n",
            "train_loss: 0.5877\n",
            "train_loss: 0.5836\n",
            "train_loss: 0.5785\n",
            "train_loss: 0.5737\n",
            "train_loss: 0.5729\n",
            "train_loss: 0.5692\n",
            "train_loss: 0.5630\n",
            "train_loss: 0.5606\n",
            "train_loss: 0.5566\n",
            "train_loss: 0.5513\n",
            "train_loss: 0.5482\n",
            "train_loss: 0.5417\n",
            "train_loss: 0.5395\n",
            "train_loss: 0.5347\n",
            "train_loss: 0.5329\n",
            "train_loss: 0.5294\n",
            "train_loss: 0.5231\n",
            "train_loss: 0.5205\n",
            "train_loss: 0.5169\n",
            "train_loss: 0.5111\n",
            "train_loss: 0.5080\n",
            "train_loss: 0.5050\n",
            "train_loss: 0.5009\n",
            "train_loss: 0.4973\n",
            "train_loss: 0.4943\n",
            "train_loss: 0.4900\n",
            "train_loss: 0.4872\n",
            "train_loss: 0.4823\n",
            "train_loss: 0.4803\n",
            "train_loss: 0.4769\n",
            "train_loss: 0.4728\n",
            "train_loss: 0.4689\n",
            "train_loss: 0.4673\n",
            "train_loss: 0.4634\n",
            "train_loss: 0.4608\n",
            "train_loss: 0.4578\n",
            "train_loss: 0.4553\n",
            "train_loss: 0.4508\n",
            "train_loss: 0.4491\n",
            "train_loss: 0.4441\n",
            "train_loss: 0.4417\n",
            "train_loss: 0.4402\n",
            "train_loss: 0.4375\n",
            "train_loss: 0.4330\n",
            "train_loss: 0.4324\n",
            "train_loss: 0.4288\n",
            "train_loss: 0.4278\n",
            "train_loss: 0.4230\n",
            "train_loss: 0.4207\n",
            "train_loss: 0.4192\n",
            "train_loss: 0.4157\n",
            "train_loss: 0.4137\n",
            "train_loss: 0.4107\n",
            "train_loss: 0.4086\n",
            "train_loss: 0.4087\n",
            "train_loss: 0.4058\n",
            "train_loss: 0.4024\n",
            "train_loss: 0.4008\n",
            "train_loss: 0.3994\n",
            "train_loss: 0.3961\n",
            "train_loss: 0.3946\n",
            "train_loss: 0.3937\n",
            "train_loss: 0.3917\n",
            "train_loss: 0.3886\n",
            "train_loss: 0.3877\n",
            "train_loss: 0.3856\n",
            "train_loss: 0.3849\n",
            "train_loss: 0.3835\n",
            "train_loss: 0.3808\n",
            "train_loss: 0.3795\n",
            "train_loss: 0.3779\n",
            "train_loss: 0.3746\n",
            "train_loss: 0.3744\n",
            "train_loss: 0.3734\n",
            "train_loss: 0.3718\n",
            "train_loss: 0.3691\n",
            "train_loss: 0.3682\n",
            "train_loss: 0.3657\n",
            "train_loss: 0.3665\n",
            "train_loss: 0.3643\n",
            "train_loss: 0.3642\n",
            "train_loss: 0.3617\n",
            "train_loss: 0.3606\n",
            "train_loss: 0.3591\n",
            "train_loss: 0.3592\n",
            "train_loss: 0.3581\n",
            "train_loss: 0.3559\n",
            "Finish training after 266 epochs\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# train2()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "plot_learning_curve(model_loss_record, title='MF model')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "hsNO9nnXQBvP",
        "outputId": "01787b1a-86eb-4560-81ad-62766a56b2b6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "%%time\n",
        "model_loss"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16 s, sys: 0 ns, total: 16 s\n",
            "Wall time: 30.5 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.911939200758934"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "model_loss_record['dev'][-1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0368753135204316"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "del model\n",
        "model = MF().to(device)\n",
        "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)\n",
        "# plot_pred(dv_set, model, device)  # Show prediction on the validation set\n",
        "dev(dv_set, model, device)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.911939200758934"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "3iZTVn5WQFpX",
        "outputId": "c2e65627-13cd-46f9-e51b-5973eb26d865"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing**\n",
        "The predictions of your model on testing set will be stored at `pred.csv`."
      ],
      "metadata": {
        "id": "aQikz3IPiyPf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# def save_pred(preds, file):\n",
        "#     ''' Save predictions to specified file '''\n",
        "#     print('Saving results to {}'.format(file))\n",
        "#     with open(file, 'w') as fp:\n",
        "#         writer = csv.writer(fp)\n",
        "#         writer.writerow(['id', 'tested_positive'])\n",
        "#         for i, p in enumerate(preds):\n",
        "#             writer.writerow([i, p])\n",
        "\n",
        "# preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "# save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8cTuQjQQOon",
        "outputId": "30dfbdf5-3b47-4bec-a993-e306f49f47a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hints**\n",
        "\n",
        "## **Simple Baseline**\n",
        "* Run sample code\n",
        "\n",
        "## **Medium Baseline**\n",
        "* Feature selection: 40 states + 2 `tested_positive` (`TODO` in dataset)\n",
        "\n",
        "## **Strong Baseline**\n",
        "* Feature selection (what other features are useful?)\n",
        "* DNN architecture (layers? dimension? activation function?)\n",
        "* Training (mini-batch? optimizer? learning rate?)\n",
        "* L2 regularization\n",
        "* There are some mistakes in the sample code, can you find them?"
      ],
      "metadata": {
        "id": "nfrVxqJanGpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reference**\n",
        "This code is completely written by Heng-Jui Chang @ NTUEE.  \n",
        "Copying or reusing this code is required to specify the original author. \n",
        "\n",
        "E.g.  \n",
        "Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"
      ],
      "metadata": {
        "id": "9tmCwXgpot3t"
      }
    }
  ]
}